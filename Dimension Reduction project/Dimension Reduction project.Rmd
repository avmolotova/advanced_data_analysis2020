---
title: "pca"
author: "Anastasia Molotova"
date: "11 november"
output: 
  html_document:
    theme: paper
    highlight: monochrome
    toc: true
    toc_float: false
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(readr)
data <- read_csv("THE2021 2.csv")
#str(data)
```

# 1) Explore the dataset and correlations
 
I will you `DataExplorer` package which helps to explore data patterns fast.

```{r}
library(DataExplorer)
introduce(data)
```

```{r}
plot_intro(data)
```

WOW! No missing values!

```{r}
plot_histogram(data)
```
```{r}
plot_density(data)
```

Distribution is not fine, must be scaled.

```{r}
library(scales)
data[,3:11] <- as.data.frame(apply(data[,3:11], 2, rescale))
summary(data[,3:11])
```

Scaling is successful! Let's explore correlations:

First option -- heatmap

```{r}
corr <- cor(data[,3:11], method="pearson")
require(reshape2)
require(ggplot2)
ggplot(reshape2::melt(corr, varnames = c("x", "y"), value.name = "correlation"), 
       aes(x = x, y = y)) +
       geom_tile(aes(fill = correlation)) +
       scale_fill_gradient2(low = "green", mid = "yellow", high = "red",
       guide = guide_colorbar(ticks = FALSE, barheight = 5),
       limits = c(-1,1)) + 
       theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
       labs(title = "Heatmap of Correlation Matrix", x = NULL, y = NULL)
```

Second option -- `plot_correlation` (love it more due to correlation numbers)

```{r}
plot_correlation(data)
```

Well, `scores_international_outlook` and `stats_pc_intl_students`, `scores_research` and `scores_teaching` are highly correlated.

```{r eval=FALSE, include=FALSE}
plot_prcomp(data)
```

# 2) Run PCA using prcomp()

PCA itself:

```{r}
pca_scores <- prcomp(data[,3:11], center = TRUE)
str(pca_scores, give.attr = F)
```

# 3) Is it possible to produce an acceptable PCA solution on these data? Answer the question and motivate your answer.

```{r}
library(dplyr)

summary(pca_scores) # Proportion of variance explained
pca_scores$sdev ^ 2 # Eigenvalue > 1
pca.var <- pca_scores$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1) # scree plot
barplot(pca.var.per, 
        main = "Scree Plot", 
        xlab = "Principal Component", 
        ylab = "Percent Variation")
```

According to the importance of components, we can produce an acceptable PCA solution on these data, since with the 9 components we would be able to account for 100% of total variance in the data(looking at cumulative proportion). Moreover, with only PC1 accounts for >51% of total variance overall. PC2 explains >19%, PC3 explains >11% of the variance.

```{r}
screeplot(pca_scores, type = "l", npcs = 9, main = "Screeplot of the first 9 PCs")
abline(h = 1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"),
       col=c("red"), lty=5, cex=0.6)
cumpro <- cumsum(pca_scores$sdev^2 / sum(pca_scores$sdev^2))
plot(cumpro[0:9], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
abline(v = 6, col="blue", lty=5)
abline(h = 0.88759, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC6"),
       col=c("blue"), lty=5, cex=0.6)
```

From the plots, my suggestion is to reduce dimensionality from 9 to 5 by losing only about 11% of the variance.

# 4) Describe the results of PCA, explain how much variance the first PCs explain, plot the result using package 'pca3d'.

```{r include=FALSE}
require(FactoMineR)
pcan <- PCA(data[, 3:11])
pcan$var$contrib[,1:5]
```

PC1 represents mostly stats_student_staff_ratio.
PC2 represents scores_industry_income, stats_female_share.
PC3 stands for stats_female_share(again) and scores_teaching.
Pc4 represents stats_student_staff_ratio, stats_female_share(again), stats_pc_intl_students, stats_number_students,scores_teaching.
PC5 represents stats_number_students, stats_pc_intl_students, stats_student_staff_ratio, stats_female_share(again).


```{r}
library(pca3d)
pca2d(pca_scores)
```

# 5) Are the best universities located in the US and Canada? Create a binary variable for US and Canada vs the rest, and use it for colouring the PC plot. (8/10)

```{r}
data = data %>% mutate(bin = 
                         case_when(
                           data$location == "United States" ~ 1,
                           data$location == "Canada" ~ 1,
                           TRUE ~ 0
                         ))
pca2d(pca_scores, group = data$bin)
```

# 6)* Add PC coordinates to the dataset and use t-test on PC1 for the binary variable you created.

```{r}
pca_data <- data.frame(
  X=pca_scores$x[,1],
  test = data$bin)

t.test(pca_data$test, pca_data$X)
```

So, we can reject the null hypothesis and say that there are differences in the means of two group exists.

# 7)* Make a ggplot of the PCA solution and turn it into a plotly graph.

```{r}
library(stringr)
data$name = str_replace_all(data$name, "ï¿½", "") 
#there were some troubles with encoding due to which database has these strange things and ggplot was not able to draw a plot, i deleted them

pca_data <- data.frame(name=data[,1],
  X=pca_scores$x[,1],
  Y=pca_scores$x[,2])
#pca_data$location = as.factor(pca_data$location)
ggplot(data = pca_data, aes(x = X, y = Y, label = name)) +
  geom_text() +
  xlab(paste("PC1 - ", pca.var.per[1], "%", sep = "")) +
  ylab(paste("PC2 - ", pca.var.per[2], "%", sep = "")) +
  theme_bw() +
  ggtitle("My PCA Graph")
```

To be honest, this looks like a black blob...
Turning into plotly:

```{r}
library(plotly)
ggplotly(p = ggplot2::last_plot())
```

